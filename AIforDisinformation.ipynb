{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "HgFn0FTvak3i"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing"
      ],
      "metadata": {
        "id": "HgFn0FTvak3i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from bs4 import BeautifulSoup\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "\n",
        "def remove_html_tags(raw_html):\n",
        "    return BeautifulSoup(raw_html, \"html.parser\").get_text()\n",
        "\n",
        "def remove_special_chars(text):\n",
        "    return re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
        "\n",
        "def remove_stopwords(text):\n",
        "    tokens = word_tokenize(text)\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    return ' '.join([word for word in tokens if word.lower() not in stop_words])\n",
        "\n",
        "def normalize(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    return text.strip()\n",
        "\n",
        "def preprocess_text(raw_html):\n",
        "    text = remove_html_tags(raw_html)\n",
        "    text = normalize(text)\n",
        "    text = remove_special_chars(text)\n",
        "    text = remove_stopwords(text)\n",
        "    return text\n",
        "\n",
        "# test\n",
        "if __name__ == \"__main__\":\n",
        "    sample_html = \"<html><body><h1>This is a test</h1><p>Hello world!</p></body></html>\"\n",
        "    print(preprocess_text(sample_html))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NynUVbyCct5J",
        "outputId": "ed05882e-0b44-4901-a0e2-91655e1742fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "testhello world\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### converting audio to text"
      ],
      "metadata": {
        "id": "mm5JR4HTBaFV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U openai-whisper"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "23eCI5XVCTu8",
        "outputId": "fb3d610f-8503-4523-ec67-8b088cf4d419",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai-whisper\n",
            "  Downloading openai_whisper-20250625.tar.gz (803 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/803.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m286.7/803.2 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m803.2/803.2 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (10.7.0)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (0.60.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (2.0.2)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (0.9.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (2.6.0+cu124)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (4.67.1)\n",
            "Requirement already satisfied: triton>=2 in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (3.2.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba->openai-whisper) (0.43.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken->openai-whisper) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken->openai-whisper) (2.32.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->openai-whisper)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->openai-whisper)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->openai-whisper) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2025.7.9)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->openai-whisper) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m69.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m87.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m53.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m111.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: openai-whisper\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20250625-py3-none-any.whl size=803979 sha256=24c10ab9936465fbf8969a19dce88dd7c4ddf471457eab7d0d439cbc5bc0092e\n",
            "  Stored in directory: /root/.cache/pip/wheels/32/d2/9a/801b5cc5b2a1af2e280089b71c326711a682fc1d50ea29d0ed\n",
            "Successfully built openai-whisper\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, openai-whisper\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 openai-whisper-20250625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.makedirs(\"images\", exist_ok=True)\n",
        "os.makedirs(\"audios\", exist_ok=True)"
      ],
      "metadata": {
        "id": "AYg70u-egZX0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "pptcvqQGgeG9",
        "outputId": "0e8950ce-bcf2-491c-f0cd-5ac993e23cd2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-a75e4460-2637-43cc-84d7-4a93d36b8b29\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-a75e4460-2637-43cc-84d7-4a93d36b8b29\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving news.mp3 to news (1).mp3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "shutil.move(\"news.mp3\", \"audios/news.mp3\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "j2K30xIJgn0k",
        "outputId": "7abf0434-8851-459d-9065-671946cd67ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'audios/news.mp3'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "import os\n",
        "\n",
        "def transcribe_audio(file_path):\n",
        "    model = whisper.load_model(\"base\")  # you can change to \"small\", \"medium\", etc.\n",
        "    print(f\"Transcribing: {file_path} ...\")\n",
        "    result = model.transcribe(file_path)\n",
        "    return result[\"text\"]\n",
        "\n",
        "def process_audio_folder(folder_path, output_folder=\"transcriptions\"):\n",
        "    os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "    for filename in os.listdir(folder_path):\n",
        "        if filename.lower().endswith((\".mp3\", \".wav\", \".m4a\")):\n",
        "            file_path = os.path.join(folder_path, filename)\n",
        "            transcript = transcribe_audio(file_path)\n",
        "\n",
        "            base_name = os.path.splitext(filename)[0]\n",
        "            output_file = os.path.join(output_folder, base_name + \".txt\")\n",
        "            with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
        "                f.write(transcript)\n",
        "\n",
        "    print(\"All audio files transcribed.\")\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    process_audio_folder(\"audios\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hBWT0n6neWzI",
        "outputId": "df04c236-76a8-4d7b-dedf-84a8194795f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████████████████████████████████| 139M/139M [00:03<00:00, 46.6MiB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribing: audios/news.mp3 ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All audio files transcribed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### applying OCR with images"
      ],
      "metadata": {
        "id": "E8MOhLi2hTAV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "xeILrmrQhAxi",
        "outputId": "66c9547c-969c-42b0-9bd6-1f4e1cabb595"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-121f80cb-3c94-48ad-b0f5-de893ae3f2d2\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-121f80cb-3c94-48ad-b0f5-de893ae3f2d2\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving fake_news.jpg to fake_news.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "shutil.move(\"fake_news.jpg\", \"images/fake_news.jpg\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "X6xF9Yd4hQgT",
        "outputId": "0e064a6c-1892-4955-a5e5-43f5fa3604a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'images/fake_news.jpg'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt install tesseract-ocr\n",
        "!pip install pytesseract"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pxOUDmO9h313",
        "outputId": "720d7f64-dae7-46c0-b33a-4dd56915f370"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "tesseract-ocr is already the newest version (4.1.1-2.1build1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 35 not upgraded.\n",
            "Collecting pytesseract\n",
            "  Downloading pytesseract-0.3.13-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from pytesseract) (24.2)\n",
            "Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from pytesseract) (11.2.1)\n",
            "Downloading pytesseract-0.3.13-py3-none-any.whl (14 kB)\n",
            "Installing collected packages: pytesseract\n",
            "Successfully installed pytesseract-0.3.13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import pytesseract\n",
        "import os\n",
        "\n",
        "def ocr_image(image_path):\n",
        "    try:\n",
        "        text = pytesseract.image_to_string(Image.open(image_path))\n",
        "        return text.strip()\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {image_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "def process_folder(folder_path, output_folder=\"ocr_results\"):\n",
        "    os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "    for filename in os.listdir(folder_path):\n",
        "        if filename.lower().endswith((\".png\", \".jpg\", \".jpeg\", \".tiff\")):\n",
        "            image_path = os.path.join(folder_path, filename)\n",
        "            print(f\"Processing: {filename}\")\n",
        "            extracted_text = ocr_image(image_path)\n",
        "\n",
        "            if extracted_text:\n",
        "                base_name = os.path.splitext(filename)[0]\n",
        "                output_file = os.path.join(output_folder, base_name + \".txt\")\n",
        "                with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
        "                    f.write(extracted_text)\n",
        "\n",
        "    print(\"OCR completed for all images.\")\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    process_folder(\"images\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dZ4v0w8vhmi2",
        "outputId": "252a6067-5148-46dd-a229-6ced80251424"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing: fake_news.jpg\n",
            "OCR completed for all images.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LLM"
      ],
      "metadata": {
        "id": "0sjlyEjUcuzc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install groq wikipedia-api ddgs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "l8zfUTlHqlzD",
        "outputId": "c5f61d93-cf47-474a-be2b-41ebfafc0c73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: groq in /usr/local/lib/python3.11/dist-packages (0.30.0)\n",
            "Requirement already satisfied: wikipedia-api in /usr/local/lib/python3.11/dist-packages (0.8.1)\n",
            "Collecting ddgs\n",
            "  Downloading ddgs-9.2.3-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from groq) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from groq) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from groq) (2.11.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.11/dist-packages (from groq) (4.14.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from wikipedia-api) (2.32.3)\n",
            "Requirement already satisfied: click>=8.1.8 in /usr/local/lib/python3.11/dist-packages (from ddgs) (8.2.1)\n",
            "Requirement already satisfied: primp>=0.15.0 in /usr/local/lib/python3.11/dist-packages (from ddgs) (0.15.0)\n",
            "Requirement already satisfied: lxml>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from ddgs) (5.4.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->groq) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq) (2025.7.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->wikipedia-api) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->wikipedia-api) (2.4.0)\n",
            "Downloading ddgs-9.2.3-py3-none-any.whl (30 kB)\n",
            "Installing collected packages: ddgs\n",
            "Successfully installed ddgs-9.2.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "GROQ_API_KEY = \"\""
      ],
      "metadata": {
        "id": "iSsXckuBqjZQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from groq import Groq\n",
        "\n",
        "class QwenChatbot:\n",
        "  def __init__(self, api_key):\n",
        "    self.client = Groq(\n",
        "        api_key=api_key,\n",
        "    )\n",
        "\n",
        "  def summarize_prompt(self, claims):\n",
        "    completion = self.client.chat.completions.create(\n",
        "        model=\"qwen/qwen3-32b\",\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": (\n",
        "                  \"You are a fact-checking assistant. When the user makes a claim or shares news, \"\n",
        "                  \"summarize it for the user and rephrase it to a search prompt to be used in the search engine.\"\n",
        "                  \"You only need to return the search prompt, do not reply anything unrelevant\"\n",
        "                ),\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": claims,\n",
        "            }\n",
        "        ],\n",
        "        temperature=0.2,\n",
        "        max_completion_tokens=4096,\n",
        "        top_p=0.95,\n",
        "        reasoning_format=\"hidden\"\n",
        "    )\n",
        "    return completion.choices[0].message.content\n",
        "\n",
        "  def check_truthiness(self, search_results, claim):\n",
        "    # system prompt\n",
        "    grading_prompt = \"\"\"\n",
        "    You are tasked with evaluating the truthfulness of a given input statement.\n",
        "    Assign a numerical score from 0 to 5 based on the following grading scale:\n",
        "\n",
        "    5 – Completely True: All claims are verifiable, accurate, and supported by reliable evidence.\n",
        "    4 – Mostly True: Minor inaccuracies may exist, but the core facts are accurate and not misleading.\n",
        "    3 – Half True: Roughly an equal mix of accurate and inaccurate or misleading information.\n",
        "    2 – Mostly False: A small element of truth exists, but the claim is mostly inaccurate or misrepresented.\n",
        "    1 – Completely False: The statement is entirely inaccurate, fabricated, or contradicted by reliable sources.\n",
        "    0 – Not Evaluated: There is insufficient information to determine the truthfulness of the statement.\n",
        "\n",
        "    Your task:\n",
        "    1. Assign a score (0–5).\n",
        "    2. Provide a concise explanation.\n",
        "    3. Clearly state which parts of the claim are TRUE and which are FALSE.\n",
        "    4. For each true/false part, cite supporting links from the following search results.\n",
        "    \"\"\"\n",
        "\n",
        "    completion = self.client.chat.completions.create(\n",
        "        model=\"qwen/qwen3-32b\",\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": grading_prompt\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": f\"Here is the claim from the user: {claim} and here is the search results: {search_results}. Cite supporting links from the following search results only\"\n",
        "            }\n",
        "        ],\n",
        "        temperature=0.5,\n",
        "        reasoning_format=\"hidden\"\n",
        "    )\n",
        "    return completion.choices[0].message.content\n"
      ],
      "metadata": {
        "id": "zMxftst-ZawU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Web Search"
      ],
      "metadata": {
        "id": "x8MDOLEhg9fw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import wikipediaapi\n",
        "\n",
        "# Replace with your API keys\n",
        "GOOGLE_FACT_CHECK_API_KEY = \"YOUR_GOOGLE_API_KEY\"\n",
        "GNEWS_API_KEY = \"YOUR_GNEWS_API_KEY\"\n",
        "\n",
        "def verify_with_google_fact_check(claim):\n",
        "    url = f\"https://factchecktools.googleapis.com/v1alpha1/claims:search?query={claim}&key={GOOGLE_FACT_CHECK_API_KEY}\"\n",
        "    response = requests.get(url)\n",
        "    if response.status_code == 200:\n",
        "        data = response.json()\n",
        "        claims = data.get(\"claims\", [])\n",
        "        return [c[\"text\"] + \" - \" + c[\"claimReview\"][0][\"textualRating\"] for c in claims] if claims else [\"No result.\"]\n",
        "    return [\"Google Fact Check API error.\"]\n",
        "\n",
        "def verify_with_gnews(claim):\n",
        "    url = f\"https://gnews.io/api/v4/search?q={claim}&token={GNEWS_API_KEY}&lang=en\"\n",
        "    response = requests.get(url)\n",
        "    if response.status_code == 200:\n",
        "        articles = response.json().get(\"articles\", [])\n",
        "        return [f\"{a['title']} - {a['source']['name']}\" for a in articles[:3]]\n",
        "    return [\"GNews API error.\"]\n",
        "\n",
        "def verify_with_wikipedia(claim):\n",
        "    wiki = wikipediaapi.Wikipedia(\n",
        "        user_agent=\"FactCheckBot/1.0 (contact: youremail@example.com)\",\n",
        "        language=\"en\"\n",
        "    )\n",
        "    page = wiki.page(claim)\n",
        "    return [page.summary[:500]] if page.exists() else [\"No Wikipedia match.\"]\n",
        "\n",
        "\n",
        "def verify_with_snopes(claim):\n",
        "    search_url = f\"https://www.snopes.com/?s={claim.replace(' ', '+')}\"\n",
        "    headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
        "    response = requests.get(search_url, headers=headers)\n",
        "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "    results = soup.select(\"article h2.entry-title a\")\n",
        "    return [link.text.strip() for link in results[:3]] if results else [\"No Snopes result.\"]\n",
        "\n",
        "def verify_claim(claim):\n",
        "    print(f\"\\n🔎 Verifying Claim: \\\"{claim}\\\"\\n\")\n",
        "\n",
        "    sources = {\n",
        "        \"Google Fact Check\": verify_with_google_fact_check(claim),\n",
        "        \"Wikipedia Summary\": verify_with_wikipedia(claim),\n",
        "        \"GNews Articles\": verify_with_gnews(claim),\n",
        "        \"Snopes Results\": verify_with_snopes(claim)\n",
        "    }\n",
        "\n",
        "    for source, results in sources.items():\n",
        "        print(f\"{source}:\")\n",
        "        for r in results:\n",
        "            print(\"  •\", r)\n",
        "        print()\n",
        "    return sources\n",
        "\n"
      ],
      "metadata": {
        "id": "tTQHWakng8vy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ddgs import DDGS\n",
        "\n",
        "def verify_with_duckduckgo(query, max_results=5):\n",
        "    results = []\n",
        "    with DDGS() as ddgs:\n",
        "        for r in ddgs.text(query, max_results=max_results):\n",
        "            title = r.get(\"title\", \"\")\n",
        "            snippet = r.get(\"body\", \"\")\n",
        "            url = r.get(\"href\", \"\")\n",
        "            results.append(f\"{title}: {snippet} (Source: {url})\")\n",
        "    return results"
      ],
      "metadata": {
        "id": "HDuWcQRJoCPj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fact Check Pipeline"
      ],
      "metadata": {
        "id": "C7lQH3a_j0CO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fact_check_pipeline(user_input):\n",
        "    chatbot = QwenChatbot(api_key=GROQ_API_KEY)\n",
        "\n",
        "    print(\"\\n Summarizing input and generating search prompt...\\n\")\n",
        "    search_prompt = chatbot.summarize_prompt(user_input)\n",
        "    print(\"Search Prompt:\\n\", search_prompt, \"\\n\")\n",
        "\n",
        "    sources = {\n",
        "        \"DuckDuckGo\": verify_with_duckduckgo(search_prompt)\n",
        "    }\n",
        "\n",
        "    combined_evidence = \"\"\n",
        "    for source, entries in sources.items():\n",
        "        combined_evidence += f\"\\n{source}:\\n\"\n",
        "        for item in entries:\n",
        "            combined_evidence += f\"• {item}\\n\"\n",
        "\n",
        "    print(\"Combined Evidence:\\n\", combined_evidence, \"\\n\")\n",
        "    print(\"Evidence collected. Evaluating truthfulness...\\n\")\n",
        "    evaluation = chatbot.check_truthiness(combined_evidence, user_input)\n",
        "    print(\"Evaluation Result:\\n\", evaluation)\n",
        "\n",
        "    return evaluation\n",
        "\n",
        "# Test\n",
        "test_claim = \"COVID-19 vaccines cause infertility\"\n",
        "fact_check_pipeline(test_claim)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "cXqmOplljwbQ",
        "outputId": "9cba09bd-16bd-4b4e-827c-6f329b229946"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Summarizing input and generating search prompt...\n",
            "\n",
            "Search Prompt:\n",
            " \"COVID-19 vaccines and infertility: scientific studies or health organization statements on potential link\" \n",
            "\n",
            "Combined Evidence:\n",
            " \n",
            "DuckDuckGo:\n",
            "• The impact of COVID-19 vaccines on fertility-A systematic ...: by D Zaçe · 2022 · Cited by 87 — Based on the studies published so far, there is no scientific proof of any association between COVID-19 vaccines and fertility impairment in men or women. (Source: https://pmc.ncbi.nlm.nih.gov/articles/PMC9464596/)\n",
            "• COVID-19 Vaccination for People Who Would Like to Have ...: 10 Sept 2024 — Despite these temporary changes in menstruation, there is no evidence that COVID-19 vaccines cause fertility problems. Research Studies of ... (Source: https://www.cdc.gov/covid/vaccines/planning-for-pregnancy.html)\n",
            "• Associations between inactivated COVID-19 vaccination ...: by D Liu · 2025 — This research fills critical knowledge gaps regarding the impact of inactivated COVID-19 vaccines on IVF outcomes and offers valuable insights ... (Source: https://www.frontiersin.org/journals/endocrinology/articles/10.3389/fendo.2025.1587251/full)\n",
            "• What doctors wish patients knew about COVID-19 vaccines ...: 29 Apr 2022 — COVID-19 vaccines don't alter fertility​​ While a National Institues of Health-funded study has found that COVID-19 vaccination is linked to a ... (Source: https://www.ama-assn.org/delivering-care/public-health/what-doctors-wish-patients-knew-about-covid-19-vaccines-and-fertility)\n",
            "• Debunking COVID-19 myths: No. COVID-19 vaccines do not cause fertility problems. After getting the vaccine, some women who get a period, also called menstruation, may have changes to ... (Source: https://www.mayoclinic.org/diseases-conditions/coronavirus/in-depth/coronavirus-myths/art-20485720)\n",
            " \n",
            "\n",
            "Evidence collected. Evaluating truthfulness...\n",
            "\n",
            "Evaluation Result:\n",
            " <think>\n",
            "Okay, let's tackle this. The user is claiming that COVID-19 vaccines cause infertility. My job is to evaluate this based on the provided sources.\n",
            "\n",
            "First, I'll go through each of the search results they provided. The first one from PMC says there's no scientific proof of any association between the vaccines and fertility impairment in men or women. That's a solid starting point. The CDC article from 2024 also mentions no evidence of fertility problems, except for temporary menstrual changes. Another study from 2025 on inactivated vaccines and IVF outcomes didn't find negative impacts. The AMA article confirms vaccines don't alter fertility, though it mentions a study on temporary menstrual changes. Finally, Mayo Clinic debunking the myth directly.\n",
            "\n",
            "Putting it all together: All the sources consistently state there's no evidence linking the vaccines to infertility. The user's claim is entirely false. The only minor note is some temporary menstrual changes, but that's not the same as infertility. So the score should be 1 because the claim is completely false. The true part is there's no evidence, and the false part is the claim about causing infertility. Each source supports the true parts against the claim's falsity. No parts of the original claim are true, so it's all false.\n",
            "</think>\n",
            "\n",
            "**Score:** 1 – **Completely False**  \n",
            "The claim that \"COVID-19 vaccines cause infertility\" is **entirely false** and contradicted by multiple reliable sources.  \n",
            "\n",
            "---\n",
            "\n",
            "### **TRUE:**  \n",
            "1. **No scientific evidence links COVID-19 vaccines to fertility impairment** in men or women.  \n",
            "   - [PMC: \"no scientific proof of any association between COVID-19 vaccines and fertility impairment\"](https://pmc.ncbi.nlm.nih.gov/articles/PMC9464596/)  \n",
            "   - [CDC: \"no evidence that COVID-19 vaccines cause fertility problems\"](https://www.cdc.gov/covid/vaccines/planning-for-pregnancy.html)  \n",
            "   - [Frontiers: \"research fills gaps regarding inactivated vaccines’ impact on IVF outcomes\"](https://www.frontiersin.org/journals/endocrinology/articles/10.3389/fendo.2025.1587251/full)  \n",
            "   - [Mayo Clinic: \"No. COVID-19 vaccines do not cause fertility problems\"](https://www.mayoclinic.org/diseases-conditions/coronavirus/in-depth/coronavirus-myths/art-20485720)  \n",
            "\n",
            "2. **Temporary menstrual changes** (not infertility) have been observed in some women post-vaccination, but no fertility issues were confirmed.  \n",
            "   - [CDC: \"temporary changes in menstruation\"](https://www.cdc.gov/covid/vaccines/planning-for-pregnancy.html)  \n",
            "   - [AMA: \"vaccines don’t alter fertility; linked to temporary menstrual changes\"](https://www.ama-assn.org/delivering-care/public-health/what-doctors-wish-patients-knew-about-covid-19-vaccines-and-fertility)  \n",
            "\n",
            "---\n",
            "\n",
            "### **FALSE:**  \n",
            "1. **The claim that vaccines \"cause infertility\" is fabricated and unsupported** by peer-reviewed studies or clinical data. All cited sources explicitly refute this.  \n",
            "   - [PMC: \"no scientific proof\"](https://pmc.ncbi.nlm.nih.gov/articles/PMC9464596/)  \n",
            "   - [CDC: \"no evidence\"](https://www.cdc.gov/covid/vaccines/planning-for-pregnancy.html)  \n",
            "   - [Mayo Clinic: \"debunked myth\"](https://www.mayoclinic.org/diseases-conditions/coronavirus/in-depth/coronavirus-myths/art-20485720)  \n",
            "\n",
            "---\n",
            "\n",
            "**Conclusion:** The claim is **completely false**. There is no credible evidence supporting an association between COVID-19 vaccines and infertility. The referenced studies emphasize the safety of vaccines regarding fertility outcomes and debunk the myth.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<think>\\nOkay, let\\'s tackle this. The user is claiming that COVID-19 vaccines cause infertility. My job is to evaluate this based on the provided sources.\\n\\nFirst, I\\'ll go through each of the search results they provided. The first one from PMC says there\\'s no scientific proof of any association between the vaccines and fertility impairment in men or women. That\\'s a solid starting point. The CDC article from 2024 also mentions no evidence of fertility problems, except for temporary menstrual changes. Another study from 2025 on inactivated vaccines and IVF outcomes didn\\'t find negative impacts. The AMA article confirms vaccines don\\'t alter fertility, though it mentions a study on temporary menstrual changes. Finally, Mayo Clinic debunking the myth directly.\\n\\nPutting it all together: All the sources consistently state there\\'s no evidence linking the vaccines to infertility. The user\\'s claim is entirely false. The only minor note is some temporary menstrual changes, but that\\'s not the same as infertility. So the score should be 1 because the claim is completely false. The true part is there\\'s no evidence, and the false part is the claim about causing infertility. Each source supports the true parts against the claim\\'s falsity. No parts of the original claim are true, so it\\'s all false.\\n</think>\\n\\n**Score:** 1 – **Completely False**  \\nThe claim that \"COVID-19 vaccines cause infertility\" is **entirely false** and contradicted by multiple reliable sources.  \\n\\n---\\n\\n### **TRUE:**  \\n1. **No scientific evidence links COVID-19 vaccines to fertility impairment** in men or women.  \\n   - [PMC: \"no scientific proof of any association between COVID-19 vaccines and fertility impairment\"](https://pmc.ncbi.nlm.nih.gov/articles/PMC9464596/)  \\n   - [CDC: \"no evidence that COVID-19 vaccines cause fertility problems\"](https://www.cdc.gov/covid/vaccines/planning-for-pregnancy.html)  \\n   - [Frontiers: \"research fills gaps regarding inactivated vaccines’ impact on IVF outcomes\"](https://www.frontiersin.org/journals/endocrinology/articles/10.3389/fendo.2025.1587251/full)  \\n   - [Mayo Clinic: \"No. COVID-19 vaccines do not cause fertility problems\"](https://www.mayoclinic.org/diseases-conditions/coronavirus/in-depth/coronavirus-myths/art-20485720)  \\n\\n2. **Temporary menstrual changes** (not infertility) have been observed in some women post-vaccination, but no fertility issues were confirmed.  \\n   - [CDC: \"temporary changes in menstruation\"](https://www.cdc.gov/covid/vaccines/planning-for-pregnancy.html)  \\n   - [AMA: \"vaccines don’t alter fertility; linked to temporary menstrual changes\"](https://www.ama-assn.org/delivering-care/public-health/what-doctors-wish-patients-knew-about-covid-19-vaccines-and-fertility)  \\n\\n---\\n\\n### **FALSE:**  \\n1. **The claim that vaccines \"cause infertility\" is fabricated and unsupported** by peer-reviewed studies or clinical data. All cited sources explicitly refute this.  \\n   - [PMC: \"no scientific proof\"](https://pmc.ncbi.nlm.nih.gov/articles/PMC9464596/)  \\n   - [CDC: \"no evidence\"](https://www.cdc.gov/covid/vaccines/planning-for-pregnancy.html)  \\n   - [Mayo Clinic: \"debunked myth\"](https://www.mayoclinic.org/diseases-conditions/coronavirus/in-depth/coronavirus-myths/art-20485720)  \\n\\n---\\n\\n**Conclusion:** The claim is **completely false**. There is no credible evidence supporting an association between COVID-19 vaccines and infertility. The referenced studies emphasize the safety of vaccines regarding fertility outcomes and debunk the myth.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def fact_check_image(file_path):\n",
        "  # Read the OCR output\n",
        "  with open(\"ocr_results/fake_news.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "      ocr_text = f.read()\n",
        "\n",
        "  # Run fact-checking on the extracted text\n",
        "  fact_check_pipeline(ocr_text)\n",
        "\n",
        "# test with image\n",
        "file_path = \"ocr_results/fake_news.txt\"\n",
        "fact_check_image(file_path)"
      ],
      "metadata": {
        "id": "Z3MnHGSfsMvR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07127cd1-0103-490f-835c-381ed5f55fe7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Summarizing input and generating search prompt...\n",
            "\n",
            "Search Prompt:\n",
            " <think>\n",
            "Okay, let's try to figure out what the user is asking here. The input looks like a bunch of random letters and maybe some typos. \"celel ele eT ee Be a a\" and \"KEE Arocatrese meow!\" don't make much sense at first glance. The user might have made a mistake while typing, or maybe they're trying to test the system with gibberish.\n",
            "\n",
            "First, I'll check if there's any coherent message hidden in the jumble. The first part \"celel ele eT ee Be a a\" could be a typo. Maybe they meant \"Check this out, here's a message\"? Not sure. The second line \"KEE Arocatrese meow!\" has \"KEE\" which might be a typo for \"Keep\" but not sure. \"Arocatrese\" doesn't seem like a real word. \"Meow!\" is clearly the sound a cat makes, so maybe they're referring to a cat-related joke or meme.\n",
            "\n",
            "The user might be sending some kind of encrypted message or a test to see if the AI can handle nonsense. Alternatively, they could be using a cipher or random letters as a prank. As a fact-checking assistant, my job is to determine if there's a claim or news to verify. But in this case, there's no clear statement to check.\n",
            "\n",
            "I should respond by asking for clarification. Let the user know I might not understand their message and ask them to rephrase or provide more details. That way, if there's an actual request or question, I can help, otherwise, it's just a case of random input.\n",
            "</think>\n",
            "\n",
            "It appears your message may be a random string of characters or a test. Could you clarify or rephrase your request? I'll do my best to assist if there's a specific claim or topic you'd like to discuss. \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-29-2880375041.py:5: RuntimeWarning: This package (`duckduckgo_search`) has been renamed to `ddgs`! Use `pip install ddgs` instead.\n",
            "  with DDGS() as ddgs:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Combined Evidence:\n",
            " \n",
            "DuckDuckGo:\n",
            "• THINK Definition & Meaning - Merriam-Webster: The meaning of THINK is to form or have in the mind. How to use think in a sentence. Synonym Discussion of Think. (Source: https://www.merriam-webster.com/dictionary/think)\n",
            "• THINK | English meaning - Cambridge Dictionary: THINK definition: 1. to believe something or have an opinion or idea: 2. to have a low opinion of someone or…. Learn more. (Source: https://dictionary.cambridge.org/dictionary/english/think)\n",
            "• Think - definition of think by The Free Dictionary: 1. To have or formulate in the mind: Think the happiest thought you can think. 2. a. To reason about or reflect on; ponder: Think how complex language is. Think the matter through. b. To … (Source: https://www.thefreedictionary.com/think)\n",
            "• THINK definition and meaning | Collins English Dictionary: If you say that you think that something is true or will happen, you mean that you have the impression that it is true or will happen, although you are not certain of the facts. (Source: https://www.collinsdictionary.com/dictionary/english/think)\n",
            "• 640 Synonyms & Antonyms for THINK | Thesaurus.com: Find 640 different ways to say THINK, along with antonyms, related words, and example sentences at Thesaurus.com. (Source: https://www.thesaurus.com/browse/think)\n",
            " \n",
            "\n",
            "Evidence collected. Evaluating truthfulness...\n",
            "\n",
            "Evaluation Result:\n",
            " <think>\n",
            "Okay, let's see. The user's claim is \"celel ele eT ee Be a a KEE Arocatrese meow!\" Hmm, that looks like random letters and sounds. Let me break it down.\n",
            "\n",
            "First, there's \"celel ele eT ee Be a a\". Then \"KEE Arocatrese meow!\". The word \"meow\" at the end makes me think this might be a playful or fictional phrase, maybe from a song or a fictional character. The rest looks like a mix of letters that don't form recognizable words. \n",
            "\n",
            "Looking at the provided search results for \"think\", the user included definitions from various dictionaries. But the claim here doesn't mention the word \"think\" at all. It seems like the user might have pasted some random text or there's a typo. Alternatively, \"Arocatrese\" sounds like a made-up name, perhaps a character or a term from a specific context not mentioned here.\n",
            "\n",
            "Since the claim doesn't reference any of the definitions provided in the search results, there's no connection to establish. The search results are about the definition of \"think\", but the user's statement is unrelated. There's no factual content here to evaluate for truthfulness because it's nonsensical or fictional. \n",
            "\n",
            "I should check if there's any hidden meaning. \"Ew! KEE Arocatrese meow!\" might be a play on words, maybe a cat character? If \"KEE\" is a sound, similar to \"meow\", but it's not a standard reference. Without additional context, it's hard to determine if any part is true. \n",
            "\n",
            "Therefore, the statement can't be evaluated because it lacks clear, verifiable claims related to the search results. There's no factual basis to assess the truthfulness.\n",
            "</think>\n",
            "\n",
            "Score: 0 – Not Evaluated  \n",
            "Explanation: The statement provided is a nonsensical string of characters (\"celel ele eT ee Be a a KEE Arocatrese meow!\") with no coherent meaning or factual claims to evaluate. The search results provided (definitions of \"think\") are unrelated to the claim.  \n",
            "TRUE: None. FALSE: None.  \n",
            "Supporting details: The input lacks any verifiable claims or logical structure to connect to the definitions of \"think\" cited in the search results.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def fact_check_audio(file_path):\n",
        "  # Read transcription\n",
        "  with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "      transcription = f.read()\n",
        "\n",
        "  # Run fact-checking on the transcription\n",
        "  fact_check_pipeline(transcription)\n",
        "\n",
        "# test with image\n",
        "file_path = \"transcriptions/news.txt\"\n",
        "fact_check_audio(file_path)"
      ],
      "metadata": {
        "id": "xWpsxj9WkGzQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c0a5bfa-f53d-44da-beeb-d138682a2f0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Summarizing input and generating search prompt...\n",
            "\n",
            "Search Prompt:\n",
            " <think>\n",
            "Okay, let's break down the user's query. They provided a detailed text about coffee's history, impact, and effects. My task is to summarize this and rephrase into a search prompt for fact-checking.\n",
            "\n",
            "First, I need to identify the main claims. The user mentions several points: coffee's history starting in Ethiopia, the legend about a goat herder in the 9th century, its role in the Enlightenment via European coffee houses, the spread of coffee houses to Europe in the 15th century, the connection between coffee and the slave trade, the economic and social impact leading to capitalism, caffeine's effects on the body, and health benefits like reduced risk for diseases.\n",
            "\n",
            "Now, I need to check which of these claims are accurate and which might need verification. The Ethiopian origin of coffee is well-established, but the goat herder story is a common legend. The association with the Enlightenment might be an overstatement, but historical records do support coffee's role in intellectual hubs. The timeline of coffee houses moving to Europe in the 15th century could be a bit off; they became prominent in the 16th and 17th centuries. The link to capitalism through productivity is plausible but not the only perspective. Health benefits are supported by some studies, but the exact reductions in disease risks need confirmation.\n",
            "\n",
            "I should structure the summary to highlight each of these points and form a search query that includes the key elements: history, Enlightenment influence, caffeine effects, health benefits, and economic impact. The search prompt should be comprehensive to cover all aspects but also concise.\n",
            "</think>\n",
            "\n",
            "**Summary of Claims:**  \n",
            "The text claims that coffee, originating from Ethiopia in the 9th century, has a rich history tied to cultural and intellectual movements. It suggests coffee fueled the Enlightenment by enabling philosophical discourse in 16th–18th century coffeehouses and indirectly influenced the rise of capitalism through productivity incentives. The text also states caffeine's psychoactive effects on the body, mentions health benefits like reduced diabetes/Alzheimer’s risk, and notes coffee's role in historical contexts like slavery.  \n",
            "\n",
            "**Fact-Check Search Prompt:**  \n",
            "\"Is coffee’s role in the Enlightenment, caffeine’s health effects, and its historical impact on slavery and capitalism accurate?\"  \n",
            "\n",
            "This search will verify the accuracy of the claims about coffee’s cultural, historical, and health-related impacts discussed in the text. \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-29-2880375041.py:5: RuntimeWarning: This package (`duckduckgo_search`) has been renamed to `ddgs`! Use `pip install ddgs` instead.\n",
            "  with DDGS() as ddgs:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Combined Evidence:\n",
            " \n",
            "DuckDuckGo:\n",
            "• THINK Definition & Meaning - Merriam-Webster: The meaning of THINK is to form or have in the mind. How to use think in a sentence. Synonym Discussion of Think. (Source: https://www.merriam-webster.com/dictionary/think)\n",
            "• THINK | English meaning - Cambridge Dictionary: THINK definition: 1. to believe something or have an opinion or idea: 2. to have a low opinion of someone or…. Learn more. (Source: https://dictionary.cambridge.org/dictionary/english/think)\n",
            "• Think - definition of think by The Free Dictionary: 1. To have or formulate in the mind: Think the happiest thought you can think. 2. a. To reason about or reflect on; ponder: Think how complex language is. Think the matter through. b. To … (Source: https://www.thefreedictionary.com/think)\n",
            "• THINK definition and meaning | Collins English Dictionary: If you say that you think that something is true or will happen, you mean that you have the impression that it is true or will happen, although you are not certain of the facts. (Source: https://www.collinsdictionary.com/dictionary/english/think)\n",
            "• 640 Synonyms & Antonyms for THINK | Thesaurus.com: Find 640 different ways to say THINK, along with antonyms, related words, and example sentences at Thesaurus.com. (Source: https://www.thesaurus.com/browse/think)\n",
            " \n",
            "\n",
            "Evidence collected. Evaluating truthfulness...\n",
            "\n",
            "Evaluation Result:\n",
            " <think>\n",
            "Okay, let's tackle this. The user wants me to evaluate the truthfulness of their claim about coffee's history, effects, and related facts. First, I need to break down each part of the statement and check against reliable sources.\n",
            "\n",
            "Starting with the first part: \"By the time you finish watching this video, 8 million cups of coffee will have been drunk all over the world.\" I need to verify if 8 million cups are consumed globally every minute. Let me think. The claim later says 2 billion cups a day. 2 billion divided by 24 hours gives about 83 million per hour, which is around 1.38 million per minute. Wait, the initial claim is 8 million per minute, which is way higher than that calculation. That seems off. Maybe they meant per day? Wait, the user's example mentions \"by the time you finish watching this video\"—assuming a 2-3 minute video, but the math doesn't add up. So that part is likely exaggerated. Let me check coffee consumption stats. According to the National Coffee Association, the U.S. alone drinks about 400 million cups daily. Globally, 2 billion is cited, so 2 billion daily would be roughly 2.3 million per hour, 38,000 per minute. So 8 million per minute is incorrect. So the first part is FALSE.\n",
            "\n",
            "Next, coffee history. \"Coffee has been consumed for at least 1.5 thousand years.\" The earliest references are from Ethiopia around the 9th-15th century? Wait, 1.5 thousand years is 1500 years ago, which would be around 500 AD. But the first credible accounts are from 15th century. So 1500 years is incorrect. So that part is FALSE.\n",
            "\n",
            "The story about the goat herder in Ethiopia. The user mentions a 9th century goat herder named Cowldy. Wait, the common legend is about Kaldi, a goat herder in Ethiopia, in the 9th century. But the name here is misspelled or made up. So this is likely true, but the name isn't correct. However, the existence of this story is real, so the core fact is TRUE but with a fabricated name. So TRUE but with fabrication.\n",
            "\n",
            "Sufis of Yemen roasted coffee seeds. That's accurate. According to coffee history, Sufi monks in Yemen started roasting beans for their stimulating effect. TRUE.\n",
            "\n",
            "Coffee houses in the Ottoman Empire in the 15th century. Yes, the first coffee houses (qahveh khaneh) were in the Ottoman Empire. TRUE.\n",
            "\n",
            "Spread to Europe in following centuries. Coffee houses came to Venice in the 16th century, so this is TRUE.\n",
            "\n",
            "Habermas and the Enlightenment. Jürgen Habermas did write about the role of coffeehouses in facilitating public discourse leading to the Enlightenment. TRUE. Voltaire's coffee consumption is a common anectode, though exact numbers vary; he did drink a lot. TRUE.\n",
            "\n",
            "Connection to the Enlightenment and scientific progress. The statement that coffee fueled the Enlightenment is a popular narrative, supported by some historians. So TRUE.\n",
            "\n",
            "Coffee and the Enlightenment leading to democracy/scientific discoveries. TRUE, as coffeehouses were hubs of intellectual exchange.\n",
            "\n",
            "Coffee and the slave trade. The French and Brazilian plantations using African slaves: TRUE. Coffee was a cash crop that relied on slavery, especially in the 18th-19th centuries. TRUE.\n",
            "\n",
            "Coffee breaks and capitalism. The idea that coffee was given to workers to boost productivity is a historical reference to companies like those in the 20th century. TRUE, but the phrasing may need sources. TRUE.\n",
            "\n",
            "2 billion cups a day and $90 billion industry. TRUE. The 2023 estimates are around 2.25 billion cups daily and the industry is over $200 billion. The $90 billion is likely pre-2010 data, but the general idea is correct. So the core facts are TRUE, though the exact numbers might be outdated.\n",
            "\n",
            "Caffeine mechanism: Binds to adenosine receptors, increases alertness. TRUE. Adenosine is known to slow the body down, caffeine blocks it. TRUE.\n",
            "\n",
            "Health effects: Caffeine's effects on heart rate, alertness, etc., TRUE. Max caffeine for adults is 400mg, about 3-4 cups. Side effects at higher doses. TRUE. Health benefits against diabetes, Parkinson's, supported by studies. TRUE.\n",
            "\n",
            "So compiling this: The initial 8 million cups per minute is FALSE. The 1.5k years is FALSE. The fabricated name Cowldy is FALSE, but the Kaldi story is TRUE. Some parts like coffee's role in Enlightenment, slave trade, etc., are TRUE. The health effects and caffeine mechanisms are TRUE. The coffee consumption numbers (2b cups) are TRUE. So the overall statement has a mix of TRUE and FALSE elements.\n",
            "</think>\n",
            "\n",
            "**Score: 3 – Half True**  \n",
            "The claim mixes accurate historical and biological information with significant inaccuracies or embellishments.  \n",
            "\n",
            "**TRUE Elements:**  \n",
            "1. **Coffee's History and Cultural Impact**:  \n",
            "   - Coffee originated in Ethiopia and spread via Sufi monks in Yemen.  \n",
            "   - Coffee houses in the Ottoman Empire and Europe played roles in Enlightenment-era intellectual exchanges.  \n",
            "   - Voltaire and other philosophers consumed large amounts of coffee, and coffeehouses were hubs for discussion.  \n",
            "   - Coffee was linked to slavery, particularly in French and Brazilian plantations during the 18th–19th centuries.  \n",
            "   - Caffeine's mechanism (blocking adenosine receptors) and health benefits (reduced diabetes/Parkinson’s risk) are scientifically validated.  \n",
            "\n",
            "**FALSE/Unverified Elements:**  \n",
            "1. **Cup Consumption Claims**:  \n",
            "   - **Claim**: \"8 million cups drunk by the time you finish this video.\"  \n",
            "     - **False**: Global daily consumption is ~2.25 billion cups (*National Coffee Association*), which is ~3 million per minute. Claiming 8 million per minute is **exaggerated**.  \n",
            "   - **Claim**: \"2 billion cups consumed daily\" (later stated in the text) is **true** but used inconsistently to justify the 8 million/minute exaggeration.  \n",
            "\n",
            "2. **Historical Inaccuracies**:  \n",
            "   - **Claim**: \"Consumed for at least 1,500 years.\"  \n",
            "     - **False**: Coffee’s documented use begins in the 15th century, not 500 AD.  \n",
            "   - **Claim**: \"9th-century goat herder 'Cowldy' saw goats eating coffee berries.\"  \n",
            "     - **Partially True**: The legend involves a goat herder named **Kaldi**, not \"Cowldy.\" The core story (goats eating berries energizes them) is culturally accepted.  \n",
            "\n",
            "3. **Causal Oversimplifications**:  \n",
            "   - **Claim**: \"Without coffee, we might not have the Enlightenment.\"  \n",
            "     - **Misleading**: While coffeehouses facilitated discourse, they were not the *sole* driver of the Enlightenment. This is a **popular theory** (e.g., Habermas), but overstated as a definitive cause.  \n",
            "\n",
            "4. **Unverified Health Claims**:  \n",
            "   - **Claim**: \"Toxic effects like seizures after 12 cups\" is **partially true** (high caffeine toxicity is documented) but **oversimplified**—individual factors vary.  \n",
            "\n",
            "**Supporting Sources**:  \n",
            "- Coffee’s global history: [Coffee Bean History: How Did Coffee Discover?](https://www.thecoffeebean.com/learn/history-coffee)  \n",
            "- Caffeine mechanisms: [Caffeine: Mechanism of Action](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6182502/)  \n",
            "- Coffee industry stats: [National Coffee Association, USA](https://www.ncausa.org/About-Coffee/Statistics)  \n",
            "- Health effects of caffeine: [Health Effects of Coffee and Caffeine](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5096725/)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0XwqRVKhntI_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}